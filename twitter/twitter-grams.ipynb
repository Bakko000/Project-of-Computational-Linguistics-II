{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #pacchetto per espressioni regolari\n",
    "import os #pacchetto per muoversi nelle cartelle\n",
    "import sys\n",
    "sys.path.append('..')  # Add parent directory to the Python path\n",
    "from utils.helpers import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conllu_dir = 'data/profiling_output/11226/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents = []\n",
    "for file_name in os.listdir(conllu_dir):\n",
    "    file_path = os.path.join(conllu_dir, file_name)\n",
    "    document = Document(file_path)\n",
    "    load_document_sentences(document)\n",
    "    all_documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ho - appena - visto - l' - ultima - puntata - e - quando - ho - iniziato - sta - serie - tv - frank - mi - faceva - ridere - ora - mi - fa - solo - incazzare - .\n",
      "\n",
      "_________________\n",
      "\n",
      "#shameless - #6x12\n",
      "\n",
      "_________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_document = all_documents[0]\n",
    "for sentence in sample_document.sentences[:2]:\n",
    "    tokens = [token.word for token in sentence.tokens]\n",
    "    print(' - '.join(tokens))\n",
    "    print('\\n_________________\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_documents_ngrams(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WORD_1_Ho': 1,\n",
       " 'WORD_1_appena': 1,\n",
       " 'WORD_1_visto': 1,\n",
       " \"WORD_1_l'\": 1,\n",
       " 'WORD_1_ultima': 1,\n",
       " 'WORD_1_puntata': 1,\n",
       " 'WORD_1_e': 1,\n",
       " 'WORD_1_quando': 1,\n",
       " 'WORD_1_ho': 1,\n",
       " 'WORD_1_iniziato': 1,\n",
       " 'WORD_1_sta': 1,\n",
       " 'WORD_1_serie': 1,\n",
       " 'WORD_1_tv': 1,\n",
       " 'WORD_1_frank': 1,\n",
       " 'WORD_1_mi': 2,\n",
       " 'WORD_1_faceva': 1,\n",
       " 'WORD_1_ridere': 1,\n",
       " 'WORD_1_ora': 1,\n",
       " 'WORD_1_fa': 1,\n",
       " 'WORD_1_solo': 1,\n",
       " 'WORD_1_incazzare': 1,\n",
       " 'WORD_1_.': 1,\n",
       " 'WORD_2_Ho_appena': 1,\n",
       " 'WORD_2_appena_visto': 1,\n",
       " \"WORD_2_visto_l'\": 1,\n",
       " \"WORD_2_l'_ultima\": 1,\n",
       " 'WORD_2_ultima_puntata': 1,\n",
       " 'WORD_2_puntata_e': 1,\n",
       " 'WORD_2_e_quando': 1,\n",
       " 'WORD_2_quando_ho': 1,\n",
       " 'WORD_2_ho_iniziato': 1,\n",
       " 'WORD_2_iniziato_sta': 1,\n",
       " 'WORD_2_sta_serie': 1,\n",
       " 'WORD_2_serie_tv': 1,\n",
       " 'WORD_2_tv_frank': 1,\n",
       " 'WORD_2_frank_mi': 1,\n",
       " 'WORD_2_mi_faceva': 1,\n",
       " 'WORD_2_faceva_ridere': 1,\n",
       " 'WORD_2_ridere_ora': 1,\n",
       " 'WORD_2_ora_mi': 1,\n",
       " 'WORD_2_mi_fa': 1,\n",
       " 'WORD_2_fa_solo': 1,\n",
       " 'WORD_2_solo_incazzare': 1,\n",
       " 'WORD_2_incazzare_.': 1,\n",
       " 'CHAR_1_H': 1,\n",
       " 'CHAR_1_o': 8,\n",
       " 'CHAR_1_ ': 23,\n",
       " 'CHAR_1_a': 16,\n",
       " 'CHAR_1_p': 3,\n",
       " 'CHAR_1_e': 10,\n",
       " 'CHAR_1_n': 6,\n",
       " 'CHAR_1_v': 3,\n",
       " 'CHAR_1_i': 10,\n",
       " 'CHAR_1_s': 7,\n",
       " 'CHAR_1_t': 7,\n",
       " 'CHAR_1_l': 4,\n",
       " \"CHAR_1_'\": 1,\n",
       " 'CHAR_1_u': 3,\n",
       " 'CHAR_1_m': 4,\n",
       " 'CHAR_1_q': 1,\n",
       " 'CHAR_1_d': 2,\n",
       " 'CHAR_1_h': 2,\n",
       " 'CHAR_1_z': 3,\n",
       " 'CHAR_1_r': 6,\n",
       " 'CHAR_1_f': 3,\n",
       " 'CHAR_1_k': 1,\n",
       " 'CHAR_1_c': 2,\n",
       " 'CHAR_1_.': 1,\n",
       " 'CHAR_2_Ho': 1,\n",
       " 'CHAR_2_o ': 6,\n",
       " 'CHAR_2_ a': 1,\n",
       " 'CHAR_2_ap': 1,\n",
       " 'CHAR_2_pp': 1,\n",
       " 'CHAR_2_pe': 1,\n",
       " 'CHAR_2_en': 1,\n",
       " 'CHAR_2_na': 1,\n",
       " 'CHAR_2_a ': 7,\n",
       " 'CHAR_2_ v': 1,\n",
       " 'CHAR_2_vi': 1,\n",
       " 'CHAR_2_is': 1,\n",
       " 'CHAR_2_st': 2,\n",
       " 'CHAR_2_to': 2,\n",
       " 'CHAR_2_ l': 1,\n",
       " \"CHAR_2_l'\": 1,\n",
       " \"CHAR_2_' \": 1,\n",
       " 'CHAR_2_ u': 1,\n",
       " 'CHAR_2_ul': 1,\n",
       " 'CHAR_2_lt': 1,\n",
       " 'CHAR_2_ti': 1,\n",
       " 'CHAR_2_im': 1,\n",
       " 'CHAR_2_ma': 1,\n",
       " 'CHAR_2_ p': 1,\n",
       " 'CHAR_2_pu': 1,\n",
       " 'CHAR_2_un': 1,\n",
       " 'CHAR_2_nt': 1,\n",
       " 'CHAR_2_ta': 3,\n",
       " 'CHAR_2_at': 2,\n",
       " 'CHAR_2_ e': 1,\n",
       " 'CHAR_2_e ': 4,\n",
       " 'CHAR_2_ q': 1,\n",
       " 'CHAR_2_qu': 1,\n",
       " 'CHAR_2_ua': 1,\n",
       " 'CHAR_2_an': 2,\n",
       " 'CHAR_2_nd': 1,\n",
       " 'CHAR_2_do': 1,\n",
       " 'CHAR_2_ h': 1,\n",
       " 'CHAR_2_ho': 1,\n",
       " 'CHAR_2_ i': 2,\n",
       " 'CHAR_2_in': 2,\n",
       " 'CHAR_2_ni': 1,\n",
       " 'CHAR_2_iz': 1,\n",
       " 'CHAR_2_zi': 1,\n",
       " 'CHAR_2_ia': 1,\n",
       " 'CHAR_2_ s': 3,\n",
       " 'CHAR_2_se': 1,\n",
       " 'CHAR_2_er': 2,\n",
       " 'CHAR_2_ri': 2,\n",
       " 'CHAR_2_ie': 1,\n",
       " 'CHAR_2_ t': 1,\n",
       " 'CHAR_2_tv': 1,\n",
       " 'CHAR_2_v ': 1,\n",
       " 'CHAR_2_ f': 3,\n",
       " 'CHAR_2_fr': 1,\n",
       " 'CHAR_2_ra': 2,\n",
       " 'CHAR_2_nk': 1,\n",
       " 'CHAR_2_k ': 1,\n",
       " 'CHAR_2_ m': 2,\n",
       " 'CHAR_2_mi': 2,\n",
       " 'CHAR_2_i ': 2,\n",
       " 'CHAR_2_fa': 2,\n",
       " 'CHAR_2_ac': 1,\n",
       " 'CHAR_2_ce': 1,\n",
       " 'CHAR_2_ev': 1,\n",
       " 'CHAR_2_va': 1,\n",
       " 'CHAR_2_ r': 1,\n",
       " 'CHAR_2_id': 1,\n",
       " 'CHAR_2_de': 1,\n",
       " 'CHAR_2_re': 2,\n",
       " 'CHAR_2_ o': 1,\n",
       " 'CHAR_2_or': 1,\n",
       " 'CHAR_2_so': 1,\n",
       " 'CHAR_2_ol': 1,\n",
       " 'CHAR_2_lo': 1,\n",
       " 'CHAR_2_nc': 1,\n",
       " 'CHAR_2_ca': 1,\n",
       " 'CHAR_2_az': 1,\n",
       " 'CHAR_2_zz': 1,\n",
       " 'CHAR_2_za': 1,\n",
       " 'CHAR_2_ar': 1,\n",
       " 'CHAR_2_ .': 1,\n",
       " 'WORD_1_#shameless': 1,\n",
       " 'WORD_1_#6x12': 1,\n",
       " 'WORD_2_#shameless_#6x12': 1,\n",
       " 'CHAR_1_#': 2,\n",
       " 'CHAR_1_6': 1,\n",
       " 'CHAR_1_x': 1,\n",
       " 'CHAR_1_1': 1,\n",
       " 'CHAR_1_2': 1,\n",
       " 'CHAR_2_#s': 1,\n",
       " 'CHAR_2_sh': 1,\n",
       " 'CHAR_2_ha': 1,\n",
       " 'CHAR_2_am': 1,\n",
       " 'CHAR_2_me': 1,\n",
       " 'CHAR_2_el': 1,\n",
       " 'CHAR_2_le': 1,\n",
       " 'CHAR_2_es': 1,\n",
       " 'CHAR_2_ss': 1,\n",
       " 'CHAR_2_s ': 1,\n",
       " 'CHAR_2_ #': 1,\n",
       " 'CHAR_2_#6': 1,\n",
       " 'CHAR_2_6x': 1,\n",
       " 'CHAR_2_x1': 1,\n",
       " 'CHAR_2_12': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_document.features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
