{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dim = 128\n",
    "dir = 'itwac'\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "sql_path = f'{parent_dir}/{dir}/itwac{dim}.sqlite'\n",
    "txt_path = f'{parent_dir}/{dir}/itwac{dim}.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(sql_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(txt_path, 'w+') as out_file:\n",
    "    for embedding in cur.execute(\"SELECT * FROM store\"):\n",
    "        str_embedding = [str(el) for el in embedding[:-1]]\n",
    "        out_file.write('\\t'.join(str_embedding)+'\\n')\n",
    "\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dim = 128\n",
    "embeddings_path = f'itwac/itwac{embeddings_dim} (1).txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_embeddings(src_path):\n",
    "    embeddings = dict()\n",
    "    for line in open(src_path, 'r'):\n",
    "        line = line.strip().split('\\t')\n",
    "        word = line[0]\n",
    "        embedding = line[1:]\n",
    "        embedding = [float(comp) for comp in embedding] # convertiamo le componenti dell'embedding in float\n",
    "        embeddings[word] = np.asarray(embedding) # trasformiamo la lista delle componenti in un vettore di numpy\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = load_word_embeddings(parent_dir+\"/\"+embeddings_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09829128, -0.00466396,  0.12274315, -0.00645867,  0.02171866,\n",
       "       -0.01775092,  0.20173289, -0.0126764 , -0.13903011,  0.14330961,\n",
       "        0.15038787, -0.00662153,  0.03522438,  0.05580687, -0.06235559,\n",
       "        0.16190079,  0.13125402,  0.09466209, -0.02967671,  0.06027041,\n",
       "        0.00226344, -0.04958551,  0.14477645, -0.12636545, -0.07517902,\n",
       "       -0.0059378 , -0.15247029, -0.07902947,  0.05534033, -0.06163132,\n",
       "       -0.04358011, -0.11407799, -0.05476963,  0.00276546,  0.04666484,\n",
       "       -0.02525456,  0.12073468,  0.14676426, -0.00958022,  0.05849574,\n",
       "       -0.13112271, -0.04931208,  0.05483235, -0.00634756, -0.21491098,\n",
       "        0.05190172,  0.1771792 ,  0.02620396,  0.06802528, -0.08378372,\n",
       "        0.0625739 ,  0.04612483, -0.12579846, -0.05673553, -0.02175681,\n",
       "       -0.19563943,  0.08836281,  0.09511665,  0.1184418 , -0.09940016,\n",
       "        0.05089193, -0.0161554 ,  0.04401183, -0.03545505,  0.04018058,\n",
       "        0.13875584,  0.10942651,  0.03830871,  0.08303873,  0.0132618 ,\n",
       "       -0.04568123, -0.00400613, -0.1356106 ,  0.05514534, -0.07236817,\n",
       "       -0.0685998 ,  0.03771403, -0.16922323,  0.00518852, -0.02480138,\n",
       "       -0.066734  , -0.15318146,  0.02272361, -0.06768468,  0.07380426,\n",
       "       -0.13995747, -0.09205799,  0.05859702, -0.09730155, -0.02521276,\n",
       "        0.11631256,  0.05730847,  0.00228108,  0.01509271, -0.00061365,\n",
       "        0.16568103, -0.03857726,  0.08954733, -0.04815894, -0.01086136,\n",
       "        0.00753549,  0.01092281, -0.09415296, -0.02933624,  0.16784027,\n",
       "        0.10891367, -0.02955305, -0.04508689, -0.0002467 , -0.06413051,\n",
       "        0.05644571, -0.07409131,  0.00310994, -0.02220298,  0.10326934,\n",
       "        0.02357078,  0.21926755,  0.06989494,  0.11199928, -0.10216472,\n",
       "       -0.04426594, -0.06311237,  0.01181522, -0.04046022, -0.15095848,\n",
       "       -0.06841758,  0.06296661,  0.06039588])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings['vedersi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valore minimo = -0.46603721380233765\n",
      "Valore massimo = 0.4841637909412384\n"
     ]
    }
   ],
   "source": [
    "min_value = 99999\n",
    "max_value = -99999\n",
    "for word in embeddings:\n",
    "    for comp in embeddings[word]:\n",
    "        if comp > max_value:\n",
    "            max_value = comp\n",
    "        elif comp < min_value:\n",
    "            min_value = comp\n",
    "\n",
    "print(f'Valore minimo = {min_value}')\n",
    "print(f'Valore massimo = {max_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['mela', 'pera', 'banana', 'arancia', 'kiwi', 'mandarino', 'automobile', 'camion', 'pullman', 'moto', 'bici', 'autobus']\n",
    "\n",
    "embs = [embeddings[word] for word in words] \n",
    "embs = np.stack(embs, axis=0) # la funzione stack \"attacca\" una lista di vettori, creando una matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 128)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "reduced_embs = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=3).fit_transform(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(reduced_embs[:,0], reduced_embs[:,1])\n",
    "for i, word in enumerate(words):\n",
    "    ax.annotate(word, (reduced_embs[i,0]+0.5, reduced_embs[i, 1]+0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conllu_dir = 'profiling_output/11152'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "all_documents_paths = []\n",
    "for file_name in os.listdir(conllu_dir):\n",
    "    file_path = os.path.join(conllu_dir, file_name)\n",
    "    all_documents_paths.append(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_digits(text):\n",
    "    try:\n",
    "      val = int(text)\n",
    "    except:\n",
    "      text = re.sub('\\d', '@Dg', text)\n",
    "      return text\n",
    "    if val >= 0 and val < 2100:\n",
    "      return str(val)\n",
    "    else:\n",
    "      return \"DIGLEN_\" + str(len(str(val)))\n",
    "\n",
    "def normalize_text(word):\n",
    "    if \"http\" in word or (\".\" in word and \"/\" in word):\n",
    "      word = str(\"___URL___\")\n",
    "      return word\n",
    "    if len(word) > 26:\n",
    "      return \"__LONG-LONG__\"\n",
    "    new_word = get_digits(word)\n",
    "    if new_word != word:\n",
    "      word = new_word\n",
    "    if word[0].isupper():\n",
    "      word = word.capitalize()\n",
    "    else:\n",
    "      word = word.lower()\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_from_file(src_path):\n",
    "    document_tokens = []\n",
    "    lines_to_skip = 0\n",
    "    take_pos = False\n",
    "    for line in open(src_path, 'r'):\n",
    "        # print(f'\\nRiga: {line.strip()}')\n",
    "        if line[0].isdigit():\n",
    "            splitted_line = line.strip().split('\\t')\n",
    "            if '-' in splitted_line[0]:\n",
    "                # print('Ho trovato un - ')\n",
    "                skip_ids = splitted_line[0].split('-')\n",
    "                # print('Indici da saltare', skip_ids)\n",
    "                lines_to_skip = int(skip_ids[1]) - int(skip_ids[0]) + 1 # l'indice ci indica quali righe saltare\n",
    "                take_pos = True # booleano che indica che dobbiamo prendere la pos della prossima parola\n",
    "                word = normalize_text(splitted_line[1])\n",
    "                pos = splitted_line[3]\n",
    "                token = {\n",
    "                    'word': word,\n",
    "                    'pos': '_'\n",
    "                }\n",
    "                # print(f'Preso token {word}')\n",
    "                document_tokens.append(token)\n",
    "            else:\n",
    "                if lines_to_skip == 0:\n",
    "                    \n",
    "                    word = normalize_text(splitted_line[1])\n",
    "                    pos = splitted_line[3]\n",
    "                    token = {\n",
    "                        'word': word,\n",
    "                        'pos': pos\n",
    "                    }\n",
    "                    # print(f'Preso token {word}')\n",
    "                    document_tokens.append(token)\n",
    "                if take_pos:\n",
    "                    pos = splitted_line[3]\n",
    "                    document_tokens[-1]['pos'] = pos\n",
    "                    take_pos = False\n",
    "                lines_to_skip = max(0, lines_to_skip-1)\n",
    "    return document_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents = []\n",
    "\n",
    "for document_path in all_documents_paths:\n",
    "    document_tokens = get_tokens_from_file(document_path)\n",
    "    all_documents.append(document_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': '\"', 'pos': 'PUNCT'},\n",
       " {'word': 'Gay', 'pos': 'PROPN'},\n",
       " {'word': 'Pride', 'pos': 'PROPN'},\n",
       " {'word': '?', 'pos': 'PUNCT'},\n",
       " {'word': 'Solo', 'pos': 'ADV'},\n",
       " {'word': 'folklore', 'pos': 'NOUN'},\n",
       " {'word': '\"', 'pos': 'PUNCT'},\n",
       " {'word': '.', 'pos': 'PUNCT'},\n",
       " {'word': 'A', 'pos': 'ADP'},\n",
       " {'word': 'Novara', 'pos': 'PROPN'},\n",
       " {'word': 'il', 'pos': 'DET'},\n",
       " {'word': 'sindaco', 'pos': 'NOUN'},\n",
       " {'word': 'leghista', 'pos': 'ADJ'},\n",
       " {'word': 'nega', 'pos': 'VERB'},\n",
       " {'word': 'il', 'pos': 'DET'},\n",
       " {'word': 'patrocinio', 'pos': 'NOUN'},\n",
       " {'word': 'ed', 'pos': 'CCONJ'},\n",
       " {'word': 'Ã¨', 'pos': 'AUX'},\n",
       " {'word': 'polemica', 'pos': 'NOUN'},\n",
       " {'word': '\"', 'pos': 'PUNCT'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_documents[0][:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings_mean(document_embeddings):\n",
    "    sum_array = np.sum(document_embeddings, axis=0)\n",
    "    mean_array = np.divide(sum_array, len(document_embeddings))\n",
    "    return mean_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_filtered_embeddings_mean(document_tokens):\n",
    "    document_embeddings = []\n",
    "    \n",
    "    for token in document_tokens:\n",
    "        word = token['word']\n",
    "        pos = token['pos']\n",
    "        if word in embeddings and pos in ['ADJ', 'NOUN', 'VERB']:\n",
    "            document_embeddings.append(embeddings[word])\n",
    "    \n",
    "    if len(document_embeddings) == 0:\n",
    "        mean_document_embeddings = np.zeros(embeddings_dim)\n",
    "    else:\n",
    "        mean_document_embeddings = compute_embeddings_mean(document_embeddings)\n",
    "    return mean_document_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_filtered_embeddings_sep_means(document_tokens):\n",
    "    adj_embeddings = []\n",
    "    noun_embeddings = []\n",
    "    verb_embeddings = []\n",
    "    \n",
    "    for token in document_tokens:\n",
    "        word = token['word']\n",
    "        pos = token['pos']\n",
    "        if word in embeddings and pos in ['ADJ']:\n",
    "            adj_embeddings.append(embeddings[word])\n",
    "        elif word in embeddings and pos in ['NOUN']:\n",
    "            noun_embeddings.append(embeddings[word])\n",
    "        elif word in embeddings and pos in ['VERB']:\n",
    "            verb_embeddings.append(embeddings[word])\n",
    "    \n",
    "    if len(adj_embeddings) == 0:\n",
    "        mean_adj_embeddings = np.zeros(embeddings_dim)\n",
    "    else:\n",
    "        mean_adj_embeddings = compute_embeddings_mean(adj_embeddings)\n",
    "        \n",
    "    if len(noun_embeddings) == 0:\n",
    "        mean_noun_embeddings = np.zeros(embeddings_dim)\n",
    "    else:\n",
    "        mean_noun_embeddings = compute_embeddings_mean(noun_embeddings)\n",
    "        \n",
    "    if len(verb_embeddings) == 0:\n",
    "        mean_verb_embeddings = np.zeros(embeddings_dim)\n",
    "    else:\n",
    "        mean_verb_embeddings = compute_embeddings_mean(verb_embeddings)  \n",
    "    \n",
    "    \n",
    "    mean_document_embeddings = np.concatenate([mean_adj_embeddings, mean_noun_embeddings, mean_verb_embeddings], axis=None)\n",
    "    return mean_document_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(documents):\n",
    "    dataset_features = []\n",
    "    for document_tokens in documents:\n",
    "        # document_embeddings = compute_all_embeddings_mean(document_tokens)\n",
    "        document_embeddings = compute_filtered_embeddings_mean(document_tokens)\n",
    "        # document_embeddings = compute_filtered_embeddings_sep_means(document_tokens)\n",
    "        dataset_features.append(document_embeddings)\n",
    "    return dataset_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = extract_features(all_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 128)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_features), len(all_features[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_list(all_documents_paths):\n",
    "    labels = []\n",
    "    for document_path in all_documents_paths:\n",
    "        document_path = document_path[:-len('.conllu')]\n",
    "        splitted_file_path = document_path.split('#')\n",
    "        genre = splitted_file_path[2]\n",
    "        gender = splitted_file_path[3]\n",
    "        labels.append(gender)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = create_label_list(all_documents_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F', 'F', 'M', 'M', 'F', 'F', 'F', 'M', 'M', 'M']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(all_features, all_labels, all_documents_paths):\n",
    "    train_features, train_labels = [], []\n",
    "    test_features, test_labels = [], []\n",
    "    \n",
    "    for features, label,  document_path in zip(all_features, all_labels, all_documents_paths):\n",
    "        if 'training' in document_path:\n",
    "            train_features.append(features)\n",
    "            train_labels.append(label)\n",
    "        else:\n",
    "            test_features.append(features)\n",
    "            test_labels.append(label)\n",
    "    return train_features, train_labels, test_features, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 200, 200)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features, train_labels, test_features, test_labels = train_test_split(all_features, all_labels, all_documents_paths)\n",
    "len(train_features), len(train_labels), len(test_features), len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "# X_train = np.stack(train_features, axis=0)\n",
    "X_train = scaler.fit_transform(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'C': 0.1, 'dual': True}\n",
      "Best score found: 0.605\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Define the parameter grid to search through\n",
    "param_grid = {\n",
    "    'C': [0.1, 0.01, 0.001],  # Regularization parameter\n",
    "    'dual': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize SVM with linear kernel\n",
    "svc = LinearSVC()\n",
    "\n",
    "# Initialize GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=5, refit=True)\n",
    "\n",
    "# Fit the grid search to your data\n",
    "grid_search.fit(X_train, train_labels)\n",
    "\n",
    "# Get mean test scores across folds\n",
    "mean_test_scores = grid_search.cv_results_['mean_test_score']\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best score found:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(test_features)\n",
    "# Get the best estimator (model) found by grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Now, you can use this best_model to make predictions on new data\n",
    "# For example, if you have new data X_new, you can predict its labels as follows:\n",
    "predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.50      0.61      0.55       100\n",
      "           M       0.49      0.38      0.43       100\n",
      "\n",
      "    accuracy                           0.49       200\n",
      "   macro avg       0.49      0.49      0.49       200\n",
      "weighted avg       0.49      0.49      0.49       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, confusion_matrix\n",
    "test_predictions = predictions\n",
    "print(classification_report(test_labels, test_predictions, zero_division=0)) # output_dict=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "y_train = np.asarray(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 40\n",
      "160 40\n",
      "160 40\n",
      "160 40\n",
      "160 40\n"
     ]
    }
   ],
   "source": [
    "splitter = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "folds = list(splitter.split(X_train))\n",
    "\n",
    "for i in range(len(folds)):\n",
    "    print(len(folds[i][0]), len(folds[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy fold 1: 0.65\n",
      "Accuracy fold 2: 0.675\n",
      "Accuracy fold 3: 0.575\n",
      "Accuracy fold 4: 0.85\n",
      "Accuracy fold 5: 0.65\n"
     ]
    }
   ],
   "source": [
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "# for i, (train_ids, test_ids) in enumerate(splitter.split(X_train)):\n",
    "for i in range(len(folds)):\n",
    "    train_ids = folds[i][0]\n",
    "    test_ids = folds[i][1]\n",
    "\n",
    "\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "\n",
    "    fold_X_test = X_train[test_ids]\n",
    "    fold_y_test = y_train[test_ids]\n",
    "\n",
    "    kfold_svc = LinearSVC(dual=True, C=0.1)\n",
    "    kfold_svc.fit(fold_X_train, fold_y_train)\n",
    "    fold_y_pred = kfold_svc.predict(fold_X_test)\n",
    "    fold_accuracy = accuracy_score(fold_y_test, fold_y_pred)\n",
    "\n",
    "    all_y_true += fold_y_test.tolist()\n",
    "    all_y_pred += fold_y_pred.tolist()\n",
    "    print(f\"Accuracy fold {i+1}: {fold_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.68      0.68      0.68       100\n",
      "           M       0.68      0.68      0.68       100\n",
      "\n",
      "    accuracy                           0.68       200\n",
      "   macro avg       0.68      0.68      0.68       200\n",
      "weighted avg       0.68      0.68      0.68       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(all_y_true, all_y_pred, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
